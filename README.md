      COLLEGE CODE:1123 

     COLLEGE NAME:SRI KRISHNA COLLEGE OF ENGINEERING

     DEPARTMENT:COMPUTER SCIENCE

     STUDENT NM-ID:157634251A26A85B3BB421378C9BF3EC 

     ROLL NO:112323104005

     DATE:14.05.2025

   Completed the project named as 
    
  ARTIFICIAL INTELLIGENCE-POWEREDAUTONOMOUS VEHICLES AND ROBOTICS

   SUBMITTED BY,
                              
    1.S.JAMES

TEAM MEMBERS:
   2.M.ISHWARYA
   3.P.DASPRAKASH
   4.M.DHANUSH 
   5.S.JOTHIKA

 


    Phase 5: Project Demonstration & Documentation
Title: AI-Powered  Autonomous Vehicles And Robotics



Abstract:
     This project presents an AI-powered autonomous vehicle and robotics system capable of navigating environments, detecting obstacles, and making real-time decisions without human input. Using machine learning, sensors, and computer vision, the prototype demonstrates efficient, intelligent mobility—highlighting the potential of AI in robotics and self-driving technologies.

  1.Project Demonstration

 Overview:
     The project demonstration showcases the key functionalities and real-time performance of the AI-powered autonomous vehicles and robotics system. It highlights how AI enables the system to perceive the environment, make decisions, and operate independently with minimal human intervention.

Demonstration Details:
       •  Autonomous Navigation: The vehicle successfully followed a designated path using AI algorithms and   real-time sensor data.
• Obstacle Detection and Avoidance: Integrated sensors and AI enabled the system to detect and avoid static and dynamic obstacles.
• Object Recognition: The robotic unit identified and interacted with objects using computer vision techniques.
• Task Execution: The robot performed pre-programmed tasks such as picking up or moving objects with precision.
       •  Real-Time Decision Making: AI models allowed the system to adapt to changing environments and make autonomous decisions.


  Outcome:
  The outcome demonstrated the practical potential of AI and robotics for applications in autonomous transportation, warehouse automation, and beyond.
  
 2.Project Documentation

  Overview:
       The project documentation provides a complete record of the design, development, and implementation of the AI-powered autonomous vehicles and robotics system. It includes technical specifications, system architecture, development processes, and testing results. This documentation ensures clarity, supports future enhancements, and serves as a reference for developers, stakeholders, and researchers.

 Documentation Sections:
   
    •  System Architecture: Diagrams and descriptions of hardware and software integration.
    •  Technology Stack: Details of AI models, programming languages, platforms, and hardware components used.
    •  Development Process: Step-by-step explanation of design, coding, testing, and integration.
    •  Algorithms and Models: Explanation of AI techniques used for navigation, object detection, and decision-  making.
   •  Testing & Validation: Methods used to evaluate system performance and reliability.

  Outcome:
     This ensures the project can be maintained, scaled, or replicated in the future, and serves as a valuable resource for both technical teams and stakeholders.

In Phase3

The goal of Phase 3 is to implement the core components of Autonomous Vehicles And Robotics based on the plans and innovative solutions developed during. This includes the development of the AI, chatbot interface, and the implementation of data security measures. Enables autonomous vehicles/robots to sense and interpret their environment using sensors like LiDAR, cameras, and radar, combined with AI for object detection and scene understanding. Determines the robot’s exact position within an environment and builds a map for navigation using techniques like SLAM (Simultaneous Localization and Mapping). Handles real-time decisions and controls the robot’s actions based on sensor input, path planning, and environmental changes. . Developed a finite state machine (FSM) for behavior management (e.g., stop, avoid, follow). Used PID controllers for speed and steering control. Integrated decision logic with perception and navigation modules for adaptive responses Utilized ROS for inter-process communication between modules. Implemented Wi-Fi and MQTT for remote monitoring and control. Used CAN bus for real-time communication between embedded systems Achieved low-latency, high-reliability communication across modules. 

Phase4 In

systems are the foundation of autonomous vehicles and robotics, enabling them to sense and interpret their environment. Combined data from multiple sensors to improve spatial awareness and reduce blind spots. Deployed YOLOv7 and PointNet++ for enhanced detection speed and accuracy. Applied Kalman filters and AI-based denoising to improve data quality in poor weather or low-light conditions. The improved perception system enabled dynamic path planning by constantly updating the environment model in real time.  Path planning and navigation are core functionalities that enable autonomous systems to move from a starting point to a destination while avoiding obstacles and optimizing travel time and safety.
 
